{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 导入库和config\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "from utls import shuffle_and_split,Bag,Dataloader\n",
    "import layer\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "USE_PHRASE = False # 只使用句子还是也使用句子片段"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "流程：\n",
    "\n",
    "1.处理数据<br>\n",
    "2.初始化word2vec<br>\n",
    "3.分割数据集<br>\n",
    "4.用数据集和word2vec设置dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 读取数据，并简单处理\n",
    "with open(r'.\\data\\train.tsv') as f:\n",
    "    tsvreader = csv.reader(f, delimiter='\\t')\n",
    "    temp = list(tsvreader)\n",
    "print(temp[:5])\n",
    "print(temp[-5:])\n",
    "\n",
    "data = temp[1:]\n",
    "if not USE_PHRASE:\n",
    "    data = [data[i] for i in range(len(data)) \n",
    "            if (i==0 or data[i][1]!=data[i-1][1]) ] \n",
    "print(*data[:5],sep='\\n')\n",
    "\n",
    "for i in range(len(data)):\n",
    "    data[i][1] = int(data[i][1])\n",
    "    data[i][3] = int(data[i][3])\n",
    "print(*data[:5],sep='\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 使用词袋模型\n",
    "sentences = [idata[2] for idata in data]\n",
    "sentences = sentences[0:512]\n",
    "\n",
    "vocab = Bag(sentences)\n",
    "vocab.init_vocab()\n",
    "inputlen = vocab.get_vocab_len()\n",
    "inputlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataloader\n",
    "train_rate = 0.8\n",
    "batch_size = 48\n",
    "\n",
    "train_data, valid_data = shuffle_and_split(data,train_rate)\n",
    "print(len(train_data),len(valid_data))\n",
    "\n",
    "train_loader = Dataloader(batch_size,vocab,train_data)\n",
    "valid_loader = Dataloader(batch_size,vocab,valid_data) #也是train，因为要用标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 模型\n",
    "class MyLinearModel:\n",
    "    \"\"\"耦合度较高，必须先forward，再getloss，再backward\"\"\"\n",
    "    def __init__(self,input,output,lr):\n",
    "        self.linear = layer.Linear(input,output)\n",
    "        self.softmax = layer.SoftmaxAndCrossEntropy()\n",
    "        self.input_len = input\n",
    "        self.last_input_batchsize = None\n",
    "        self.learningrate = lr\n",
    "\n",
    "        self.linear.init_param()\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"返回softmax以后的\"\"\"\n",
    "        assert isinstance(x,np.ndarray)\n",
    "        assert len(x.shape) == 2 and x.shape[1] == self.input_len\n",
    "        self.last_input_batchsize = x.shape[0]\n",
    "        x = self.linear.forward(x)\n",
    "        x = self.softmax.forward(x)\n",
    "        return x\n",
    "    def getloss(self,label):\n",
    "        \"\"\"返回loss\"\"\"\n",
    "        assert label.shape[0] == self.last_input_batchsize\n",
    "        return self.softmax.get_loss(label)\n",
    "    def backward(self):\n",
    "        mid_stream = self.softmax.backward()\n",
    "        mid_stream = self.linear.backward(mid_stream)\n",
    "        self.linear.update_param(self.learningrate)\n",
    "\n",
    "lr = 0.0001\n",
    "model = MyLinearModel(inputlen,5,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 训练\n",
    "epoch = 10\n",
    "\n",
    "for ep in range(epoch):\n",
    "    batch_num = train_loader.get_batch_nums()\n",
    "    for i in range(batch_num):\n",
    "        input_tensor,lable = train_loader[i]\n",
    "        soft_outp = model.forward(input_tensor)\n",
    "        model.getloss(lable)\n",
    "        model.backward()\n",
    "        if i%10 == 0:\n",
    "            soft_outp = soft_outp.reshape(-1,soft_outp.shape[-1])\n",
    "            print(\"batch:\",i)\n",
    "            print(\"softmax的结果:\",soft_outp[:5],sep='\\n')\n",
    "            print(\"lable:\",lable[:5])\n",
    "            \n",
    "            ans = np.argmax(soft_outp,axis=1)\n",
    "\n",
    "            right = np.sum(ans==lable)\n",
    "            print(\"accuracy：\",right/ans.shape[0])\n",
    "\n",
    "# # 验证\n",
    "valid_batch_num = valid_loader.get_batch_nums()\n",
    "valid_accuracy = 0\n",
    "for i in range(valid_batch_num):\n",
    "    input_tensor, lable = valid_loader[i]\n",
    "    soft_outp = model.forward(input_tensor)\n",
    "    ans = np.argmax(soft_outp.reshape(-1,soft_outp.shape[-1]), axis=1)\n",
    "    valid_accuracy += np.sum(ans == lable)\n",
    "print(f\"Validation Accuracy: {valid_accuracy / (valid_batch_num * batch_size):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo5use",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
